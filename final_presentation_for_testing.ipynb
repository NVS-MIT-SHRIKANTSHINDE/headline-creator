{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mxzc1hGqDPqe",
        "outputId": "b1d72591-8a54-4a37-c534-47961df47128"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hOiekgxRqdx4"
      },
      "source": [
        "## ***encoder-decoder without attention model***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sqEUXmAmFmU9",
        "outputId": "66c5b466-26dd-4015-cf33-68d18781e291"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting keras_self_attention\n",
            "  Downloading keras-self-attention-0.51.0.tar.gz (11 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from keras_self_attention) (1.26.4)\n",
            "Building wheels for collected packages: keras_self_attention\n",
            "  Building wheel for keras_self_attention (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras_self_attention: filename=keras_self_attention-0.51.0-py3-none-any.whl size=18895 sha256=864d93ae4b6693a76e2a90059e2a62a5c7fd95e5e3623484a57182202cb67e1f\n",
            "  Stored in directory: /root/.cache/pip/wheels/b8/f7/24/607b483144fb9c47b4ba2c5fba6b68e54aeee2d5bf6c05302e\n",
            "Successfully built keras_self_attention\n",
            "Installing collected packages: keras_self_attention\n",
            "Successfully installed keras_self_attention-0.51.0\n"
          ]
        }
      ],
      "source": [
        "pip install keras_self_attention"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PxhMwjyXqcKn"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "from bs4 import BeautifulSoup\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from keras_self_attention import SeqSelfAttention as AttentionLayer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from nltk.corpus import stopwords\n",
        "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Concatenate, TimeDistributed\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import warnings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Li4P_39Dql6K",
        "outputId": "3a1dab9e-446f-4f39-bb29-d5ebabba1b5b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
            "WARNING:absl:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Text Summarization Model\n",
            "========================\n",
            "\n",
            "Enter a text to summarize (or type 'exit' to quit): exit\n",
            "Exiting...\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import pickle\n",
        "\n",
        "# Load the saved models\n",
        "encoder_model = load_model('/content/drive/MyDrive/deeplab/non attention/noattention_encoder_model.h5')\n",
        "decoder_model = load_model('/content/drive/MyDrive/deeplab/non attention/noattention_decoder_model.h5')\n",
        "\n",
        "# Load the tokenizers\n",
        "with open('/content/drive/MyDrive/deeplab/non attention/noattention_source_tokenizer.pkl', 'rb') as f:\n",
        "    source_tokenizer = pickle.load(f)\n",
        "\n",
        "with open('/content/drive/MyDrive/deeplab/non attention/noattention_target_tokenizer.pkl', 'rb') as f:\n",
        "    target_tokenizer = pickle.load(f)\n",
        "\n",
        "# Reverse dictionaries for decoding\n",
        "reverse_target_word_index = target_tokenizer.index_word\n",
        "target_word_index = target_tokenizer.word_index\n",
        "reverse_source_word_index = source_tokenizer.index_word\n",
        "source_word_index = source_tokenizer.word_index\n",
        "\n",
        "# Maximum lengths (update based on your training setup)\n",
        "max_text_len = 50  # Example value; set to your actual max input length\n",
        "max_summary_len = 15  # Example value; set to your actual max summary length\n",
        "\n",
        "# Decode sequence function\n",
        "def decode_sequence(input_seq):\n",
        "    # Encode the input as state vectors.\n",
        "    e_out, e_h, e_c = encoder_model.predict(input_seq)\n",
        "\n",
        "    # Generate empty target sequence of length 1.\n",
        "    target_seq = np.zeros((1, 1))\n",
        "\n",
        "    # Populate the first word of the target sequence with the start token.\n",
        "    target_seq[0, 0] = target_word_index['sostok']\n",
        "\n",
        "    stop_condition = False\n",
        "    decoded_sentence = ''\n",
        "    while not stop_condition:\n",
        "        # Predict the next word in the sequence\n",
        "        output_tokens, h, c = decoder_model.predict([target_seq] + [e_out, e_h, e_c])\n",
        "\n",
        "        # Sample the token with the highest probability\n",
        "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "        sampled_token = reverse_target_word_index.get(sampled_token_index, '')\n",
        "\n",
        "        # Append the token to the decoded sentence\n",
        "        if sampled_token != 'eostok':\n",
        "            decoded_sentence += ' ' + sampled_token\n",
        "\n",
        "        # Exit condition: either hit max length or find stop word.\n",
        "        if sampled_token == 'eostok' or len(decoded_sentence.split()) >= (max_summary_len - 1):\n",
        "            stop_condition = True\n",
        "\n",
        "        # Update the target sequence (of length 1).\n",
        "        target_seq = np.zeros((1, 1))\n",
        "        target_seq[0, 0] = sampled_token_index\n",
        "\n",
        "        # Update internal states\n",
        "        e_h, e_c = h, c\n",
        "\n",
        "    return decoded_sentence.strip()\n",
        "\n",
        "# Preprocess user input\n",
        "def preprocess_input(input_text):\n",
        "    # Tokenize and pad the input\n",
        "    input_sequence = source_tokenizer.texts_to_sequences([input_text])\n",
        "    input_sequence = pad_sequences(input_sequence, maxlen=max_text_len, padding='post')\n",
        "    return input_sequence\n",
        "\n",
        "# Main flow for user input\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"Text Summarization Model\")\n",
        "    print(\"========================\\n\")\n",
        "\n",
        "    while True:\n",
        "        input_text = input(\"Enter a text to summarize (or type 'exit' to quit): \")\n",
        "        if input_text.lower() == 'exit':\n",
        "            print(\"Exiting...\")\n",
        "            break\n",
        "\n",
        "        # Preprocess input\n",
        "        input_sequence = preprocess_input(input_text)\n",
        "\n",
        "        # Generate summary\n",
        "        predicted_summary = decode_sequence(input_sequence)\n",
        "\n",
        "        print(\"\\nOriginal Text: \", input_text)\n",
        "        print(\"Predicted Summary: \", predicted_summary)\n",
        "        print(\"\\n\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SB2sfxsHT5_8"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "\n",
        "# Path to the image\n",
        "image_path = '/content/drive/MyDrive/deeplab/non attention/without attention5).png'\n",
        "\n",
        "# Display the image\n",
        "img = mpimg.imread(image_path)  # Read the image\n",
        "plt.imshow(img)                 # Display the image\n",
        "plt.axis('off')                 # Turn off axes for better visualization\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KvyUa8CZRN0d"
      },
      "source": [
        "## ***encoder-decoder with attention model***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fp8R5n2DPVex",
        "outputId": "6c4c6d35-9c53-43f6-caa5-9d5439286173"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: keras-self-attention in /usr/local/lib/python3.10/dist-packages (0.51.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from keras-self-attention) (1.26.4)\n"
          ]
        }
      ],
      "source": [
        "pip install keras-self-attention"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tXf5TFZGO0CG"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "from bs4 import BeautifulSoup\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from keras_self_attention import SeqSelfAttention as AttentionLayer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from nltk.corpus import stopwords\n",
        "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Concatenate, TimeDistributed\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import warnings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RMFz05KVQvCL",
        "outputId": "2f821e5b-df17-4ab1-d215-419af1d7c150"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
            "WARNING:absl:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Text Summarization Model\n",
            "========================\n",
            "\n",
            "Enter a text to summarize (or type 'exit' to quit): hello\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 883ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 372ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "\n",
            "Original Text:  hello\n",
            "Predicted Summary:  why did not rape if she was raped by men in front of\n",
            "\n",
            "\n",
            "Enter a text to summarize (or type 'exit' to quit): exit\n",
            "Exiting...\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import pickle\n",
        "\n",
        "# Load the saved models\n",
        "encoder_model2 = load_model('/content/drive/MyDrive/deeplab/attention/encoder_model.h5')\n",
        "decoder_model2 = load_model('/content/drive/MyDrive/deeplab/attention/decoder_model.h5')\n",
        "\n",
        "# Load the tokenizers\n",
        "with open('/content/drive/MyDrive/deeplab/attention/source_tokenizer.pkl', 'rb') as f:\n",
        "    source_tokenizer = pickle.load(f)\n",
        "\n",
        "with open('/content/drive/MyDrive/deeplab/attention/target_tokenizer.pkl', 'rb') as f:\n",
        "    target_tokenizer = pickle.load(f)\n",
        "\n",
        "# Reverse dictionaries for decoding\n",
        "reverse_target_word_index = target_tokenizer.index_word\n",
        "target_word_index = target_tokenizer.word_index\n",
        "reverse_source_word_index = source_tokenizer.index_word\n",
        "source_word_index = source_tokenizer.word_index\n",
        "\n",
        "# Maximum lengths (update based on your training setup)\n",
        "max_text_len = 50  # Example value; set to your actual max input length\n",
        "max_summary_len = 15  # Example value; set to your actual max summary length\n",
        "\n",
        "# Decode sequence function\n",
        "def decode_sequence2(input_seq):\n",
        "    # Encode the input as state vectors.\n",
        "    e_out, e_h, e_c = encoder_model2.predict(input_seq)\n",
        "\n",
        "    # Generate empty target sequence of length 1.\n",
        "    target_seq = np.zeros((1, 1))\n",
        "\n",
        "    # Populate the first word of the target sequence with the start token.\n",
        "    target_seq[0, 0] = target_word_index['sostok']\n",
        "\n",
        "    stop_condition = False\n",
        "    decoded_sentence = ''\n",
        "    while not stop_condition:\n",
        "        # Predict the next word in the sequence\n",
        "        output_tokens, h, c = decoder_model.predict([target_seq] + [e_out, e_h, e_c])\n",
        "\n",
        "        # Sample the token with the highest probability\n",
        "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "        sampled_token = reverse_target_word_index.get(sampled_token_index, '')\n",
        "\n",
        "        # Append the token to the decoded sentence\n",
        "        if sampled_token != 'eostok':\n",
        "            decoded_sentence += ' ' + sampled_token\n",
        "\n",
        "        # Exit condition: either hit max length or find stop word.\n",
        "        if sampled_token == 'eostok' or len(decoded_sentence.split()) >= (max_summary_len - 1):\n",
        "            stop_condition = True\n",
        "\n",
        "        # Update the target sequence (of length 1).\n",
        "        target_seq = np.zeros((1, 1))\n",
        "        target_seq[0, 0] = sampled_token_index\n",
        "\n",
        "        # Update internal states\n",
        "        e_h, e_c = h, c\n",
        "\n",
        "    return decoded_sentence.strip()\n",
        "\n",
        "# Preprocess user input\n",
        "def preprocess_input(input_text):\n",
        "    # Tokenize and pad the input\n",
        "    input_sequence = source_tokenizer.texts_to_sequences([input_text])\n",
        "    input_sequence = pad_sequences(input_sequence, maxlen=max_text_len, padding='post')\n",
        "    return input_sequence\n",
        "\n",
        "# Main flow for user input\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"Text Summarization Model\")\n",
        "    print(\"========================\\n\")\n",
        "\n",
        "    while True:\n",
        "        input_text = input(\"Enter a text to summarize (or type 'exit' to quit): \")\n",
        "        if input_text.lower() == 'exit':\n",
        "            print(\"Exiting...\")\n",
        "            break\n",
        "\n",
        "        # Preprocess input\n",
        "        input_sequence = preprocess_input(input_text)\n",
        "\n",
        "        # Generate summary\n",
        "        predicted_summary = decode_sequence(input_sequence)\n",
        "\n",
        "        print(\"\\nOriginal Text: \", input_text)\n",
        "        print(\"Predicted Summary: \", predicted_summary)\n",
        "        print(\"\\n\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UaTCk7FkT8Lq"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "\n",
        "# Path to the image\n",
        "image_path = '//content/drive/MyDrive/deeplab/attention/attention).png'\n",
        "\n",
        "# Display the image\n",
        "img = mpimg.imread(image_path)  # Read the image\n",
        "plt.imshow(img)                 # Display the image\n",
        "plt.axis('off')                 # Turn off axes for better visualization\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wkH8yRybYbjP"
      },
      "source": [
        "## **T5**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bD5RTeyjE5lV",
        "outputId": "e344dcc7-2b59-4173-a1e6-9d8cd37a73e0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['generation_config.json',\n",
              " 'special_tokens_map.json',\n",
              " 'tokenizer_config.json',\n",
              " 'spiece.model',\n",
              " 'model.safetensors',\n",
              " 'config.json',\n",
              " 'added_tokens.json']"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import zipfile\n",
        "\n",
        "# Replace 'your_file.zip' with the name of your uploaded zip file\n",
        "with zipfile.ZipFile('/content/drive/MyDrive/deeplab/T5/saved_t5_model.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('extracted_filest5')\n",
        "\n",
        "# List the files to verify extraction\n",
        "import os\n",
        "os.listdir('extracted_files')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rnbTkxcQYoSV"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yaaRSNqeYfXC",
        "outputId": "98f1971b-3e27-4458-924c-cc8613fc54e6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cpu\n",
            "Model and tokenizer loaded from /content/extracted_filest5\n",
            "Generated Summary: new zealand defeat india by wickets in od\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "# Directory to save the model\n",
        "save_directory = \"/content/extracted_filest5\"\n",
        "\n",
        "# Save function\n",
        "def save_model(model, tokenizer, directory):\n",
        "    model.save_pretrained(directory)\n",
        "    tokenizer.save_pretrained(directory)\n",
        "    print(f\"Model and tokenizer saved to {directory}\")\n",
        "\n",
        "# Load function\n",
        "def load_model(directory):\n",
        "    model = T5ForConditionalGeneration.from_pretrained(directory)\n",
        "    tokenizer = T5Tokenizer.from_pretrained(directory)\n",
        "    print(f\"Model and tokenizer loaded from {directory}\")\n",
        "    return model, tokenizer\n",
        "\n",
        "# Example usage:\n",
        "# Save the trained model and tokenizer\n",
        "# save_model(model, tokenizer, save_directory)\n",
        "\n",
        "# Reload the model and tokenizer\n",
        "loaded_model, loaded_tokenizer = load_model(save_directory)\n",
        "loaded_model.to(device)\n",
        "\n",
        "# Generate summaries using the reloaded model\n",
        "def generate_summary_with_loaded_model(text, model, tokenizer, max_length=15):\n",
        "    input_ids = tokenizer(\n",
        "        f\"summarize: {text}\", return_tensors=\"pt\", max_length=100, truncation=True\n",
        "    ).input_ids.to(device)\n",
        "    outputs = model.generate(input_ids, max_length=max_length, num_beams=4, early_stopping=True)\n",
        "    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "# Test the reloaded model\n",
        "sample_text = \"new zealand defeated india by wickets in the fourth odi at hamilton on thursday to win their first match of the five-match odi series india lost an international match under rohit sharma captaincy after 12 consecutive victories dating back to march 2018 the match witnessed india getting all out for 92 their seventh lowest total in odi cricket history.\"\n",
        "summary = generate_summary_with_loaded_model(sample_text, loaded_model, loaded_tokenizer)\n",
        "print(\"Generated Summary:\", summary)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XvitIbmwUONc"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "\n",
        "# Path to the image\n",
        "image_path = '/content/drive/MyDrive/deeplab/T5/Screenshot 2024-11-22 110957.png'\n",
        "\n",
        "# Display the image\n",
        "img = mpimg.imread(image_path)  # Read the image\n",
        "plt.imshow(img)                 # Display the image\n",
        "plt.axis('off')                 # Turn off axes for better visualization\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zK8ppA5ZgbrB"
      },
      "source": [
        "## ***bert***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v3of10gCkJoE",
        "outputId": "e8a8025b-e76e-4fc5-b141-9d3da67d7e9d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['generation_config.json',\n",
              " 'special_tokens_map.json',\n",
              " 'tokenizer_config.json',\n",
              " 'spiece.model',\n",
              " 'model.safetensors',\n",
              " 'config.json',\n",
              " 'added_tokens.json']"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import zipfile\n",
        "\n",
        "# Replace 'your_file.zip' with the name of your uploaded zip file\n",
        "with zipfile.ZipFile('/content/drive/MyDrive/deeplab/bert/trained_model.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('extracted_filesbert')\n",
        "\n",
        "# List the files to verify extraction\n",
        "import os\n",
        "os.listdir('extracted_files')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b40wShMikrEH",
        "outputId": "d366c119-63d9-4d24-aea1-edf01873271f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yGyJCkaVgbY5",
        "outputId": "483a6328-bc03-49c7-be91-0b45389ba722"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cpu\n",
            "Model and tokenizer loaded from /content/extracted_filesbert\n"
          ]
        }
      ],
      "source": [
        "from transformers import BertTokenizer, EncoderDecoderModel\n",
        "# Set device to CUDA if available, else use CPU\n",
        "import torch\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Load the model and tokenizer from the saved directory\n",
        "def load_model_and_tokenizer(load_dir='/content/extracted_filesbert'):\n",
        "    tokenizer = BertTokenizer.from_pretrained(load_dir)\n",
        "    model = EncoderDecoderModel.from_pretrained(load_dir)\n",
        "    model.to(device)\n",
        "    print(f\"Model and tokenizer loaded from {load_dir}\")\n",
        "    return model, tokenizer\n",
        "\n",
        "# Load the model\n",
        "loaded_model, loaded_tokenizer = load_model_and_tokenizer('/content/extracted_filesbert')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "buo7rcqChFsH",
        "outputId": "de6430ae-5f36-4a38-d6f9-a8c5d9518b23"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated Summary: short - swift dog jumps over dog jumps around over him working working gets congress hairs indian\n"
          ]
        }
      ],
      "source": [
        "# Generate summaries for new texts\n",
        "def generate_summary(model, tokenizer, text, max_input_length=512, max_output_length=40):\n",
        "    # Preprocess the input text\n",
        "    inputs = tokenizer(\n",
        "        [text], max_length=max_input_length, truncation=True, padding=\"max_length\", return_tensors=\"pt\"\n",
        "    ).to(device)\n",
        "\n",
        "    # Generate the summary (include decoder_start_token_id)\n",
        "    summary_ids = model.generate(\n",
        "        inputs['input_ids'],\n",
        "        max_length=max_output_length,\n",
        "        num_beams=4,\n",
        "        no_repeat_ngram_size=3,\n",
        "        early_stopping=True,\n",
        "        decoder_start_token_id=model.config.decoder_start_token_id  # Ensure this is set\n",
        "    )\n",
        "\n",
        "    # Decode the summary\n",
        "    summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
        "    return summary\n",
        "\n",
        "# Example text for summary\n",
        "text = \"The quick brown fox jumps over the lazy dog. This is just an example sentence for testing.\"\n",
        "summary = generate_summary(loaded_model, loaded_tokenizer, text)\n",
        "print(f\"Generated Summary: {summary}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mcl3jvU5J5v5",
        "outputId": "4801e733-4f12-4fe5-e81c-5d4a58140593"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated Summary: upgrad is up - up - srura - ypros worked at info assistantssssss\n"
          ]
        }
      ],
      "source": [
        "text = \"saurav kant an alumnus of upgrad and iiit-b pg program in machine learning and artificial intelligence was sr systems engineer at infosys with almost years of work experience the program and upgrad 360-degree career support helped him transition to data scientist at tech mahindra with 90% salary hike upgrad online power learning has powered lakh+ careers.\"\n",
        "summary = generate_summary(loaded_model, loaded_tokenizer, text)\n",
        "print(f\"Generated Summary: {summary}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6AZkYfiwUS29"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "\n",
        "# Path to the image\n",
        "image_path = '/content/drive/MyDrive/deeplab/bert/bert.png'\n",
        "\n",
        "# Display the image\n",
        "img = mpimg.imread(image_path)  # Read the image\n",
        "plt.imshow(img)                 # Display the image\n",
        "plt.axis('off')                 # Turn off axes for better visualization\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UsxbILqzHJym"
      },
      "source": [
        "### **finally the check**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3pQqHzRJHWy4"
      },
      "outputs": [],
      "source": [
        "\n",
        "# text = \"The quick brown fox jumps over the lazy dog. This is just an example sentence for testing.\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "OK2ELiyaHJZp",
        "outputId": "62c88331-fb65-4243-c422-c35ea040a4ff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Original Text:  new zealand defeated india by wickets in the fourth odi at hamilton on thursday to win their first match of the five-match odi series india lost an international match under rohit sharma captaincy after 12 consecutive victories dating back to march 2018 the match witnessed india getting all out for 92 their seventh lowest total in odi cricket history.\n",
            "\n",
            "\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "Predicted Summary:  india beat nz to win their first ever odi series\n",
            "\n",
            "\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
            "\n",
            "Original Text:  new zealand defeated india by wickets in the fourth odi at hamilton on thursday to win their first match of the five-match odi series india lost an international match under rohit sharma captaincy after 12 consecutive victories dating back to march 2018 the match witnessed india getting all out for 92 their seventh lowest total in odi cricket history.\n",
            "Predicted Summarywith attention:  india beat nz to win their first ever odi series\n",
            "\n",
            "\n",
            "Generated Summary bert: new zealand defeated india by wickets in the fourth odi\n",
            "\n",
            "\n",
            "Generated Summary t5: new zealand defeat india by wickets in od\n",
            "\n",
            "\n",
            "\n",
            "Original Text:   taarak mehta ka ooltah chashmah producer asit modi while talking about disha vakani who plays daya ben quitting the show said maybe true don know about the final decision my team talking with her earlier reports had suggested disha asked for hike in her fee while planning to return to the show post giving birth to her daughter.\n",
            "\n",
            "\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "Predicted Summary:  no one of the accidental it was like the accidental\n",
            "\n",
            "\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
            "\n",
            "Original Text:   taarak mehta ka ooltah chashmah producer asit modi while talking about disha vakani who plays daya ben quitting the show said maybe true don know about the final decision my team talking with her earlier reports had suggested disha asked for hike in her fee while planning to return to the show post giving birth to her daughter.\n",
            "Predicted Summarywith attention:  no one of the accidental it was like the accidental\n",
            "\n",
            "\n",
            "Generated Summary bert: ka ooltah chashmah producer asit modi\n",
            "\n",
            "\n",
            "Generated Summary t5: taarak mehta ka oo\n",
            "\n",
            "\n",
            "\n",
            "Original Text:  reliance industries chairman mukesh ambani daughter isha ambani who got married last month said she only cried at her bidaai because she felt peer pressure as everyone was crying especially her parents was emotional too but everyone around me would cry all the time she added it was very emotional affair for everyone in my family said isha.\n",
            "\n",
            "\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
            "Predicted Summary:  my family is the first person of the family of the year\n",
            "\n",
            "\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
            "\n",
            "Original Text:  reliance industries chairman mukesh ambani daughter isha ambani who got married last month said she only cried at her bidaai because she felt peer pressure as everyone was crying especially her parents was emotional too but everyone around me would cry all the time she added it was very emotional affair for everyone in my family said isha.\n",
            "Predicted Summarywith attention:  my family is the first person of the family of the year\n",
            "\n",
            "\n",
            "Generated Summary bert: daughter isha ambani who got married last month said she only cried at her bidaai\n",
            "\n",
            "\n",
            "Generated Summary t5: reliance industries chairman daughter only cried at her bidaai\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "while True:\n",
        "  input_text = input(\"Enter a text to summarize (or type 'exit' to quit): \")\n",
        "  if input_text.lower() == 'exit':\n",
        "    print(\"Exiting...\")\n",
        "    break\n",
        "\n",
        "        # Preprocess input\n",
        "  input_sequence = preprocess_input(input_text)\n",
        "\n",
        "  print(\"\\nOriginal Text: \", input_text)\n",
        "  print(\"\\n\")\n",
        "  predicted_summary = decode_sequence(input_sequence)\n",
        "  print(\"Predicted Summary: \", predicted_summary)\n",
        "  print(\"\\n\")\n",
        "\n",
        "  predicted_summary = decode_sequence2(input_sequence)\n",
        "  print(\"\\nOriginal Text: \", input_text)\n",
        "  print(\"Predicted Summarywith attention: \", predicted_summary)\n",
        "  print(\"\\n\")\n",
        "\n",
        "  text = input_text\n",
        "  summary = generate_summary(loaded_model, loaded_tokenizer, text)\n",
        "  print(f\"Generated Summary bert: {summary}\")\n",
        "\n",
        "  print(\"\\n\")\n",
        "  # sample_text = input_text\n",
        "  summary = generate_summary_with_loaded_model(text, loaded_model, loaded_tokenizer)\n",
        "  print(\"Generated Summary t5:\", summary)\n",
        "  print(\"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j9EA1sKAmFDh"
      },
      "outputs": [],
      "source": [
        "!pip install rouge_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YsQ2NA9klUKA"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from nltk.translate.bleu_score import corpus_bleu\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Generate summaries and calculate scores for 30 samples\n",
        "def generate_summary(model, tokenizer, text, max_input_length=512, max_output_length=40):\n",
        "    inputs = tokenizer(\n",
        "        [text], max_length=max_input_length, truncation=True, padding=\"max_length\", return_tensors=\"pt\"\n",
        "    ).to(device)\n",
        "\n",
        "    summary_ids = model.generate(\n",
        "        inputs['input_ids'],\n",
        "        max_length=max_output_length,\n",
        "        num_beams=4,\n",
        "        no_repeat_ngram_size=3,\n",
        "        early_stopping=True,\n",
        "        decoder_start_token_id=model.config.decoder_start_token_id\n",
        "    )\n",
        "\n",
        "    summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
        "    return summary\n",
        "\n",
        "\n",
        "ile_path = '/content/post_prewithno_start.csv'  # Replace with the path to your CSV file\n",
        "df = pd.read_csv(file_path)\n",
        "df = df.head(30)\n",
        "# Sample test cases and their expected summaries (for BLEU score)\n",
        "reference_summaries = df[\"summary\"]\n",
        "# Replace with actual model and tokenizer objects\n",
        "generated_summaries = []\n",
        "\n",
        "\n",
        "texts = df[\"text\"]\n",
        "\n",
        "# Generate summaries\n",
        "for text in texts:\n",
        "    summary = generate_summary(loaded_model, loaded_tokenizer, text)\n",
        "    generated_summaries.append(summary)\n",
        "    print(summary)\n",
        "\n",
        "\n",
        "\n",
        "# Calculate BLEU score for the generated summaries\n",
        "bleu_score = corpus_bleu([[ref.split()] for ref in reference_summaries], [gen.split() for gen in generated_summaries])\n",
        "\n",
        "print(f\"BLEU Score: {bleu_score:.4f}\")\n",
        "\n",
        "# Plot BLEU scores for 30 samples\n",
        "sample_bleu_scores = [corpus_bleu([[ref.split()] for ref in reference_summaries[i:i+1]], [gen.split() for gen in generated_summaries[i:i+1]]) for i in range(30)]\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(range(1, 31), sample_bleu_scores, marker='o', linestyle='-', color='b')\n",
        "plt.title(\"BLEU Scores for 30 Summaries\")\n",
        "plt.xlabel(\"Sample Number\")\n",
        "plt.ylabel(\"BLEU Score\")\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# Calculate additional scores (e.g., METEOR, ROUGE, etc. if needed)\n",
        "# For example, ROUGE score using rouge_score library:\n",
        "from rouge_score import rouge_scorer\n",
        "\n",
        "rouge_scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
        "rouge_scores = []\n",
        "\n",
        "for i in range(30):\n",
        "    scores = rouge_scorer.score(reference_summaries[i], generated_summaries[i])\n",
        "    rouge_scores.append(scores)\n",
        "\n",
        "# Print out average ROUGE scores\n",
        "average_rouge1 = np.mean([score['rouge1'].fmeasure for score in rouge_scores])\n",
        "average_rouge2 = np.mean([score['rouge2'].fmeasure for score in rouge_scores])\n",
        "average_rougeL = np.mean([score['rougeL'].fmeasure for score in rouge_scores])\n",
        "\n",
        "print(f\"Average ROUGE-1: {average_rouge1:.4f}\")\n",
        "print(f\"Average ROUGE-2: {average_rouge2:.4f}\")\n",
        "print(f\"Average ROUGE-L: {average_rougeL:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AGmpezrfppYR"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Plot BLEU and ROUGE scores\n",
        "rouge1_scores = [score['rouge1'].fmeasure for score in rouge_scores]\n",
        "rouge2_scores = [score['rouge2'].fmeasure for score in rouge_scores]\n",
        "rougeL_scores = [score['rougeL'].fmeasure for score in rouge_scores]\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(sample_bleu_scores, label='BLEU Scores', marker='o')\n",
        "plt.plot(rouge1_scores, label='ROUGE-1 F1', marker='o')\n",
        "plt.plot(rouge2_scores, label='ROUGE-2 F1', marker='o')\n",
        "plt.plot(rougeL_scores, label='ROUGE-L F1', marker='o')\n",
        "plt.title(\"Evaluation Metrics for 30 Samples\", fontsize=16)\n",
        "plt.xlabel(\"Sample Index\", fontsize=12)\n",
        "plt.ylabel(\"Scores\", fontsize=12)\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}